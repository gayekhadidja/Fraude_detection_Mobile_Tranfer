{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regular-material",
   "metadata": {
    "papermill": {
     "duration": 0.012516,
     "end_time": "2021-05-13T14:35:00.619392",
     "exception": false,
     "start_time": "2021-05-13T14:35:00.606876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# 2. Données\n",
    "\n",
    "Le jeu de données peut être téléchargé depuis : [https://www.kaggle.com/ntnu-testimon/paysim1](https://www.kaggle.com/ntnu-testimon/paysim1)\n",
    "\n",
    "Ce jeu de données contient des transactions d'argent mobile qui ont été générées avec le simulateur PaySim. La simulation était basée sur un échantillon de transactions réelles collectées par une entreprise qui est le fournisseur du service financier mobile actuellement en cours dans plus de 14 pays à travers le monde. Les données sont un ensemble de journaux financiers d'un mois d'un service d'argent mobile mis en place dans un pays africain.\n",
    "\n",
    "Les données sont regroupées dans un fichier CSV. Un exemple de ligne d'échantillon :\n",
    "\\`1,PAYMENT,1060.31,C429214117,1089.0,28.69,M1591654462,0.0,0.0,0,0\\`\n",
    "\n",
    "Le jeu de données contient (suivant l'exemple ci-dessus) :\n",
    "\n",
    "- **step** - représente une unité de temps dans le monde réel. Dans ce cas, 1 étape équivaut à 1 heure de temps. Total des étapes : 744 (simulation de 30 jours).\n",
    "- **type** - CASH-IN, CASH-OUT, DEBIT, PAYMENT et TRANSFER.\n",
    "- **amount** - montant de la transaction en monnaie locale.\n",
    "- **nameOrig** - client ayant initié la transaction.\n",
    "- **oldbalanceOrg** - solde initial avant la transaction.\n",
    "- **newbalanceOrig** - nouveau solde après la transaction.\n",
    "- **nameDest** - client destinataire de la transaction.\n",
    "- **oldbalanceDest** - solde initial du destinataire avant la transaction. Remarque : aucune information n'est disponible pour les clients dont le nom commence par M (commerçants).\n",
    "- **newbalanceDest** - nouveau solde du destinataire après la transaction. Remarque : aucune information n'est disponible pour les clients dont le nom commence par M (commerçants).\n",
    "- **isFraud** - Il s'agit des transactions effectuées par des agents frauduleux dans la simulation. Dans ce jeu de données spécifique, le comportement frauduleux des agents vise à tirer profit en prenant le contrôle des comptes des clients et en essayant de vider les fonds en les transférant vers un autre compte, puis en les retirant du système.\n",
    "- **isFlaggedFraud** - Le modèle commercial vise à contrôler les transferts massifs d'un compte à un autre et signale les tentatives illégales. Une tentative illégale dans ce jeu de données est une tentative de transférer plus de 200 000 lors d'une seule transaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-indianapolis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T14:35:00.649353Z",
     "iopub.status.busy": "2021-05-13T14:35:00.648165Z",
     "iopub.status.idle": "2021-05-13T14:35:01.956036Z",
     "shell.execute_reply": "2021-05-13T14:35:01.956777Z"
    },
    "papermill": {
     "duration": 1.32496,
     "end_time": "2021-05-13T14:35:01.957187",
     "exception": false,
     "start_time": "2021-05-13T14:35:00.632227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'IPython'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "\n",
    "# Model evaluations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Models from Scikit-Learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9f2e9",
   "metadata": {},
   "source": [
    "# Load and Exploration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-soundtrack",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-13T14:35:01.997999Z",
     "iopub.status.busy": "2021-05-13T14:35:01.997000Z",
     "iopub.status.idle": "2021-05-13T14:35:21.549683Z",
     "shell.execute_reply": "2021-05-13T14:35:21.549176Z"
    },
    "papermill": {
     "duration": 19.575552,
     "end_time": "2021-05-13T14:35:21.549854",
     "exception": false,
     "start_time": "2021-05-13T14:35:01.974302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162385f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c46c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb56e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347438d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4821d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre total de transactions\n",
    "total_transactions = len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montant total des transactions\n",
    "total_amount = data['amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fréquence des types de transactions\n",
    "transaction_types_frequency = data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c036b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Fréquence des types de transactions avec visualisation graphique\n",
    "transaction_types_frequency = data['type'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=transaction_types_frequency.index, y=transaction_types_frequency.values)\n",
    "plt.title('Fréquence des types de transactions')\n",
    "plt.xlabel('Type de transaction')\n",
    "plt.ylabel('Nombre de transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse du solde avant et après la transaction\n",
    "data['balance_change'] = data['newbalanceOrig'] - data['oldbalanceOrg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répartition des soldes avant et après les transactions avec visualisation graphique\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(data['oldbalanceOrg'], label='Solde avant')\n",
    "sns.kdeplot(data['newbalanceOrig'], label='Nouveau solde')\n",
    "plt.title('Répartition des soldes avant et après les transactions')\n",
    "plt.xlabel('Solde')\n",
    "plt.ylabel('Densité')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Nombre de transactions frauduleuses\n",
    "fraudulent_transactions = data[data['isFraud'] == 1]\n",
    "num_fraudulent_transactions = len(fraudulent_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pourcentage de transactions frauduleuses\n",
    "percentage_fraudulent_transactions = (num_fraudulent_transactions / total_transactions) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fréquence des transferts illégaux signalés\n",
    "flagged_fraud_transactions = data[data['isFlaggedFraud'] == 1]\n",
    "num_flagged_fraud_transactions = len(flagged_fraud_transactions)\n",
    "num_flagged_fraud_transactions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b944e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrer les transaction frauduleuse \n",
    "flagged_fraud_transactions.to_csv('transaction_frauduleuse.csv')\n",
    "transaction_frauduleuse = pd.read_csv('transaction_frauduleuse.csv')\n",
    "transaction_frauduleuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62914aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montant moyen des transactions par type\n",
    "average_amount_by_type = data.groupby('type')['amount'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118dd3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyse de la fraude par type de transaction\n",
    "fraud_by_type = fraudulent_transactions['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6318e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Taux de fraude par unité de temps\n",
    "fraud_rate_by_step = fraudulent_transactions['step'].value_counts() / total_transactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde108af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyse des transactions de commerçants\n",
    "merchant_transactions = data[data['nameDest'].str.startswith('M')]\n",
    "num_merchant_transactions = len(merchant_transactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506b23e",
   "metadata": {},
   "source": [
    " le pourcentage de transactions frauduleuses qui ont été correctement signalées (isFlaggedFraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea9cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_flagged_rate = len(flagged_fraud_transactions) / num_fraudulent_transactions\n",
    "print(\" Taux de transactions frauduleuses signalées correctement =\", correctly_flagged_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef52b8",
   "metadata": {},
   "source": [
    "##### Analyse du comportement des clients frauduleuse "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf726dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_clients_stats = fraudulent_transactions.groupby('nameOrig').agg(\n",
    "    count_amount=('amount', 'count'),\n",
    "    mean_amount=('amount', 'mean'),\n",
    "    mean_balance_change=('balance_change', 'mean')\n",
    ")\n",
    "fraudulent_clients_stats['count_amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bf14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrez les résultats dans un fichier CSV\n",
    "fraudulent_clients_stats.to_csv('Comportement_desclient_frauduleuse.csv')\n",
    "compor_client = pd.read_csv('Comportement_desclient_frauduleuse.csv')\n",
    "compor_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83724d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_clients_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a53dbc",
   "metadata": {},
   "source": [
    "L'analyse que l'on peut faire à partir des résultats montre que, en moyenne, les clients frauduleux transfèrent ou retirent des montants équivalents à leur solde, et chacun d'entre eux effectue une seule transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65033980",
   "metadata": {},
   "source": [
    " le temps moyen écoulé entre la création d'une transaction frauduleuse et sa détection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_detection_time = (fraudulent_transactions['step'] - fraudulent_transactions['step'].min()).mean()\n",
    "print(\"Temps moyen de détection des fraudes =\", fraud_detection_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23a6e1",
   "metadata": {},
   "source": [
    " la moyenne des montants pour les transactions marquées comme frauduleuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79df0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_fraudulent_amount = fraudulent_transactions['amount'].mean()\n",
    "print(\" Montant moyen de transactions frauduleuses =\", average_fraudulent_amount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c6836",
   "metadata": {},
   "source": [
    " les heures de la journée où les transactions sont les plus fréquentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea746e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_hours = data.groupby('step')['step'].count().idxmax()\n",
    "print(\" Heures de pointe =\", peak_hours)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a28f6",
   "metadata": {},
   "source": [
    "la fréquence à laquelle les soldes des comptes sont renouvelés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_renewal_rate = (data['newbalanceOrig'] > data['oldbalanceOrg']).sum() / total_transactions\n",
    "print(\"Taux de renouvellement des soldes =\", balance_renewal_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2792ae6",
   "metadata": {},
   "source": [
    "les catégories de destinataires les plus courantes dans les transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f607598",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_destination_categories = data['nameDest'].apply(lambda x: x[0] if x[0] != 'M' else 'Marchant').value_counts()\n",
    "print(\"Catégories de destinataires les plus fréquentes :\\n\", top_destination_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e202cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des catégories de destinataires les plus fréquentes avec visualisation graphique\n",
    "top_destination_categories = data['nameDest'].apply(lambda x: x[0] if x[0] != 'M' else 'Marchant').value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_destination_categories.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Répartition des catégories de destinataires')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_transaction_duration = data.groupby('type')['step'].diff().mean()\n",
    "print(\" Durée moyenne des transactions =\", average_transaction_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b55611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Évolution temporelle des transactions avec visualisation graphique\n",
    "transactions_by_time = data.groupby('step')['step'].count()\n",
    "plt.figure(figsize=(14, 6))\n",
    "transactions_by_time.plot(kind='line')\n",
    "plt.title('Évolution temporelle des transactions')\n",
    "plt.xlabel('Heure (step)')\n",
    "plt.ylabel('Nombre de transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc7da2",
   "metadata": {},
   "source": [
    "#### etude sur le variable montant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Répartition des montants de transactions par type avec visualisation graphique\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='type', y='amount', data=data)\n",
    "plt.title('Répartition des montants de transactions par type')\n",
    "plt.xlabel('Type de transaction')\n",
    "plt.ylabel('Montant de la transaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux de fraude par catégorie de destinataire avec visualisation graphique\n",
    "data['dest_category'] = data['nameDest'].apply(lambda x: x[0] if x[0] != 'M' else 'Marchant')\n",
    "fraud_rate_by_dest_category = data.groupby('dest_category')['isFraud'].mean()\n",
    "plt.figure(figsize=(10, 6))\n",
    "fraud_rate_by_dest_category.plot(kind='bar')\n",
    "plt.title('Taux de fraude par catégorie de destinataire')\n",
    "plt.xlabel('Catégorie de destinataire')\n",
    "plt.ylabel('Taux de fraude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a788e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Répartition des montants de transactions par heure avec visualisation graphique\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='step', y='amount', data=data)\n",
    "plt.title('Répartition des montants de transactions par heure')\n",
    "plt.xlabel('Heure (step)')\n",
    "plt.ylabel('Montant de la transaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Diagramme en secteurs des types de transactions frauduleuses \n",
    "fraud_by_type = fraudulent_transactions['type'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "fraud_by_type.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Répartition des types de transactions frauduleuses')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_debut = pd.to_datetime('2023-02-01')  # la date de debut \n",
    "\n",
    "# Convertir step en heures en ajoutant la date de début\n",
    "data['timestamp'] = date_debut + pd.to_timedelta(data['step'], unit='h')\n",
    "\n",
    "# Extraire le jour de la semaine et ajouter une colonne 'jour_de_la_semaine'\n",
    "data['jour_de_la_semaine'] = data['timestamp'].dt.day_name()\n",
    "\n",
    "# Visualisation du résultat\n",
    "#print(data[['step', 'timestamp', 'jour_de_la_semaine']].head())\n",
    "\n",
    "data['timestamp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea54845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrez les résultats dans un fichier CSV\n",
    "#data.to_csv('resultats_dask.csv')\n",
    "#up_data = pd.read_csv('resultats_dask.csv')\n",
    "#up_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_frauduleuse_update  = data[data['isFraud'] == 1]\n",
    "transaction_frauduleuse_update.to_csv('transaction_frauduleuse_update.csv')\n",
    "up_data = pd.read_csv('transaction_frauduleuse_update.csv')\n",
    "up_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3042172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Évolution temporelle des soldes moyens avant et après les transactions \n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(data['timestamp'], data['oldbalanceOrg'], label='Solde initial moyen', linestyle='-', color='b')\n",
    "plt.plot(data['timestamp'], data['newbalanceOrig'], label='Nouveau solde moyen', linestyle='-', color='g')\n",
    "plt.title('Évolution temporelle des soldes moyens avant et après les transactions')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Solde moyen')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ed2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montant moyen de transactions par heure avec visualisation graphique\n",
    "average_amount_by_hour = data.groupby(data['timestamp'].dt.hour)['amount'].mean()\n",
    "plt.figure(figsize=(10, 6))\n",
    "average_amount_by_hour.plot(kind='bar', color='skyblue')\n",
    "plt.title('Montant moyen de transactions par heure')\n",
    "plt.xlabel('Heure du jour')\n",
    "plt.ylabel('Montant moyen de la transaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux de fraude par jour de la semaine avec tendance lissée\n",
    "fraud_rate_by_weekday = data.groupby(data['timestamp'].dt.day_name())['isFraud'].mean()\n",
    "plt.figure(figsize=(10, 6))\n",
    "fraud_rate_by_weekday.plot(kind='line', marker='o', color='red')\n",
    "plt.title('Taux de fraude par jour de la semaine avec tendance lissée')\n",
    "plt.xlabel('Jour de la semaine')\n",
    "plt.ylabel('Taux de fraude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d793ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des variations horaires des types de transactions \n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x=data['timestamp'].dt.hour, hue=data['type'], data=data)\n",
    "plt.title('Répartition horaire des types de transactions')\n",
    "plt.xlabel('Heure du jour')\n",
    "plt.ylabel('Nombre de transactions')\n",
    "plt.legend(title='Type de transaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a9893",
   "metadata": {},
   "source": [
    " les heures de la journée où les transactions sont les plus fréquentes se situe entre 18h et 20h avec un pic en 19h. Autre constact les transaction débute entre 7h et 8h et se termine entre 0 et 1h du matin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Évolution du solde destinataire après la transaction\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(x='timestamp', y='newbalanceDest', hue='jour_de_la_semaine', data=data)\n",
    "plt.title(\"Évolution du solde destinataire après la transaction par jour\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Solde destinataire après la transaction\")\n",
    "plt.legend(title='Jour de la semaine')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c579edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_transactions = data[data['isFraud']==1]\n",
    "fraudulent_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des variations horaires des types de transactions \n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x=fraudulent_transactions['timestamp'].dt.hour, hue=data['isFraud'], data=data)\n",
    "plt.title('Répartition horaire des types de transactions')\n",
    "plt.xlabel('Heure du jour')\n",
    "plt.ylabel('Nombre de transactions')\n",
    "plt.legend(title='Type de transaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des montants de transactions frauduleuses par jour de la semaine avec visualisation graphique\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='jour_de_la_semaine', y='amount', data=fraudulent_transactions)\n",
    "plt.title('Distribution des montants de transactions frauduleuses par jour de la semaine')\n",
    "plt.xlabel('Jour de la semaine')\n",
    "plt.ylabel('Montant de la transaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la variation horaire des transactions frauduleuses \n",
    "fraudulent_hours = fraudulent_transactions['timestamp'].dt.hour\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(fraudulent_hours, bins=24, kde=True)\n",
    "plt.title('Analyse de la variation horaire des transactions frauduleuses')\n",
    "plt.xlabel('Heure du jour')\n",
    "plt.ylabel('Nombre de transactions frauduleuses')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Montant moyen des transactions par type de transaction \n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='type', y='amount', data=data, hue='isFraud', ci=None)\n",
    "plt.title('Montant moyen des transactions par type de transaction')\n",
    "plt.xlabel('Type de transaction')\n",
    "plt.ylabel('Montant moyen de la transaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Histogramme des montants de transactions frauduleuses avec visualisation graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(fraudulent_transactions['amount'], bins=30, kde=True)\n",
    "plt.title('Distribution des montants de transactions frauduleuses')\n",
    "plt.xlabel('Montant de la transaction')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49044f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  'timestamp' est au format datetime\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# Calculer le taux de fraude par heure\n",
    "fraud_rate_by_hour = data.groupby('timestamp')['isFraud'].mean()\n",
    "\n",
    "# KPI : Évolution du taux de fraude par timestamp avec visualisation graphique\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(fraud_rate_by_hour.index, fraud_rate_by_hour.values, marker='o', linestyle='-', color='r')\n",
    "plt.title('Évolution du taux de fraude par timestamp')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Taux de fraude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e958e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de la fréquence des types de transactions par jour de la semaine avec visualisation graphique\n",
    "transaction_types_by_weekday = data.groupby(['jour_de_la_semaine', 'type']).size().unstack()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(transaction_types_by_weekday, cmap='Blues', annot=True, fmt='d')\n",
    "plt.title('Fréquence des types de transactions par jour de la semaine')\n",
    "plt.xlabel('Type de transaction')\n",
    "plt.ylabel('Jour de la semaine')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répartition des montants de transactions par timestamp avec visualisation graphique\n",
    "plt.figure(figsize=(14, 8))\n",
    "fig1 = plt.scatter(data['timestamp'], data['amount'])\n",
    "#fig2 = px.scatter(data, x=\"timestamp\", y=\"amount\")\n",
    "plt.title('Répartition des montants de transactions par timestamp')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Montant de la transaction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répartition des montants de transactions par timestamp avec visualisation graphique\n",
    "plt.figure(figsize=(14, 8))\n",
    "fig1 = plt.scatter(fraudulent_transactions['timestamp'], fraudulent_transactions['amount'])\n",
    "#fig2 = px.scatter(data, x=\"timestamp\", y=\"amount\")\n",
    "plt.title('Répartition des montants de transactions frauduleuse par timestamp')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Montant de la transaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299436cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe3da0",
   "metadata": {},
   "source": [
    "##  Exécution des différents KPI avec duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb373cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "duckdb.query(\"SELECT nameDest, amount FROM df where oldbalanceDest == 0.0\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7857b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spécifier l'axe des x et l'axe des y\n",
    "ax = df['isFraud'].value_counts().plot(\n",
    "kind='pie', # Pour créer un graphique circulaire avec matplotlib,vous pouvez utiliser la fonction 'pie'\n",
    "figsize=(8,4),# déterminer la taille du graphique\n",
    "autopct = '%.2f%%', \n",
    "labels=df['isFraud'].value_counts().index, #Fournir les étiquettes pour chaque type de TRANACTION \n",
    "legend = True,\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "'Distributions des transactions fauduleuse et non frauduleuse', # Titre du graphique\n",
    "loc ='center', # Positionner au centre\n",
    "fontsize=12, # Dimension du texte\n",
    "fontweight='bold' # type de caractere\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b20deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les client qui font des transaction massive de compte en comme \n",
    "\n",
    "Client_trans_massive  = duckdb.query(\"select nameOrig , amount from df where isFlaggedFraud == 1\").to_df()\n",
    "Client_trans_massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Client_trans_massive.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentabilité_transaction = duckdb.sql(\"\"\"SELECT \n",
    "    type,\n",
    "    sum(amount) AS montant_moyen_type_transaction\n",
    "FROM df\n",
    "GROUP BY type\"\"\").to_df()\n",
    "rentabilité_transaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"isFlaggedFraud\"] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"isFraud\"]==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pourcentage_massive_fraude  = duckdb.sql(\"\"\"\n",
    "    SELECT nameOrig, amount , isFraud\n",
    "    FROM df\n",
    "    WHERE isFraud = 1 AND isFlaggedFraud = 1\n",
    "\"\"\").to_df()\n",
    "\n",
    "pourcentage_massive_fraude['isFraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "taux_de_fraud = duckdb.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS total_transactions,\n",
    "           SUM(CASE WHEN isFraud = 1 THEN 1 ELSE 0 END) AS total_fraudulent_transactions,\n",
    "           (SUM(CASE WHEN isFraud = 1 THEN 1 ELSE 0 END) * 100.0) / COUNT(*) AS fraud_rate\n",
    "    FROM df\n",
    "\"\"\").to_df()\n",
    "\n",
    "taux_de_fraud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "taux_succe_transfer = duckdb.sql( \"\"\"\n",
    "    SELECT COUNT(*) AS total_transfers,\n",
    "           SUM(CASE WHEN type = 'TRANSFER' THEN 1 ELSE 0 END) AS successful_transfers,\n",
    "           (SUM(CASE WHEN type = 'TRANSFER' THEN 1 ELSE 0 END) * 100.0) / COUNT(*) AS success_transfer_rate\n",
    "    FROM df\n",
    "\"\"\"\n",
    ").to_df()\n",
    "\n",
    "taux_succe_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact des transaction frauduleuse \n",
    "fraudulent_transactions_impact_query = duckdb.sql(\"\"\"\n",
    "    SELECT SUM(amount) AS total_amount_fraudulent_transactions\n",
    "    FROM df\n",
    "    WHERE isFraud = 1\n",
    "\"\"\").to_df()\n",
    "\n",
    "fraudulent_transactions_impact_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffbe03e",
   "metadata": {},
   "source": [
    "##### Taux de Succès des Transfert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "taux_succé_transfer = duckdb.sql(\"\"\"SELECT \n",
    "    SUM(CASE WHEN type = 'TRANSFER' THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS success_transfer_rate\n",
    "FROM df\"\"\").to_df()\n",
    "\n",
    "taux_succé_transfer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a93609",
   "metadata": {},
   "source": [
    "##### Taux de Signalement des Transactions Massives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "taux_signalisation_transaction_massive =  duckdb.sql(\"\"\"SELECT \n",
    "    round(SUM(CASE WHEN amount > 200000 THEN 1 ELSE 0 END) * 100.0 / COUNT(*),2) AS flagged_transactions_rate\n",
    "FROM df\"\"\").to_df()\n",
    "\n",
    "taux_signalisation_transaction_massive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c02f4",
   "metadata": {},
   "source": [
    "##### Ratio de Fraude par Type de Transaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_par_type_transaction= duckdb.sql(\"\"\"SELECT \n",
    "    type,\n",
    "    round(SUM(CASE WHEN isFraud = 1 THEN 1 ELSE 0 END) * 100/ COUNT(*),3) AS fraud_ratio_by_type\n",
    "FROM df\n",
    "GROUP BY type\"\"\").to_df()\n",
    "\n",
    "fraud_par_type_transaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dabbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"\"\"SELECT \n",
    "    type,\n",
    "    COUNT(*) AS nombre_transactions,\n",
    "    round(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) AS pourcentage_total\n",
    "FROM df\n",
    "GROUP BY type\n",
    "\"\"\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c150169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472843b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CASH_OUT', round(df['type'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('PAYMENT', round(df['type'].value_counts()[1]/len(df) * 100,2), '% of the dataset')\n",
    "print('CASH_IN', round(df['type'].value_counts()[2]/len(df) * 100,2), '% of the dataset')\n",
    "print('TRANSFER', round(df['type'].value_counts()[3]/len(df) * 100,2), '% of the dataset')\n",
    "print('DEBIT', round(df['type'].value_counts()[4]/len(df) * 100,2), '% of the dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fd4d1",
   "metadata": {},
   "source": [
    "#####   Fréquence des Transactions par Client :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d45a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequence_transaction_client = duckdb.sql(\"\"\"SELECT \n",
    "    nameOrig,\n",
    "    COUNT(*) AS transaction_count_per_client,\n",
    "    (COUNT(*) * 1.0) / (SELECT COUNT(*) FROM df) AS frequency\n",
    "FROM df\n",
    "GROUP BY nameOrig\n",
    "\"\"\").to_df()\n",
    "frequence_transaction_client['transaction_count_per_client'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ca617",
   "metadata": {},
   "source": [
    "#### Évolution du Solde Moyen des Comptes Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa042881",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_solde_moyen_compte_client = duckdb.sql(\"\"\"SELECT \n",
    "    nameOrig,\n",
    "    AVG(newbalanceOrig - oldbalanceOrg) AS average_balance_change\n",
    "FROM df\n",
    "GROUP BY nameOrig\n",
    "\"\"\").to_df()\n",
    "\n",
    "evolution_solde_moyen_compte_client.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02937884",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['isFraud'].value_counts()[0]/len(df) * 100,2)\n",
    "print(df['isFraud'].value_counts()[1]/len(df) * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_catégorielle = ['type', 'nameOrig', 'nameDest']\n",
    "\n",
    "colonnes_existantes = df.columns.tolist()\n",
    "colonnes_a_supprimer = [colonne for colonne in var_catégorielle if colonne in colonnes_existantes]\n",
    "\n",
    "df_num = df.drop(columns=colonnes_a_supprimer)\n",
    "df_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c40dc",
   "metadata": {},
   "source": [
    "## Conservation des observations ou type = transfer ou cash_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3721e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = dt.query('type == \"TRANSFER\" or type == \"CASH_OUT\"')\n",
    "data1['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = df[df['isFraud'] ==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spécifier l'axe des x et l'axe des y\n",
    "ax = fraud_data['type'].value_counts().plot(\n",
    "kind='pie', \n",
    "figsize=(8,4),\n",
    "autopct = '%.2f%%', \n",
    "labels=fraud_data['type'].value_counts().index,\n",
    "legend = True,\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "'Distributions des fraudes suivants les différents types', \n",
    "loc ='center',\n",
    "fontsize=12, \n",
    "fontweight='bold'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114974eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spécifier l'axe des x et l'axe des y\n",
    "ax = data['type'].value_counts().plot(\n",
    "kind='pie', \n",
    "figsize=(8,4),\n",
    "autopct = '%.2f%%', \n",
    "labels=df['type'].value_counts().index,\n",
    "legend = True,\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "'Distribution des types de transaction', \n",
    "loc ='center',\n",
    "fontsize=12, \n",
    "fontweight='bold'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des transactions frauduleuse suivant les différents type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_catégorielle = ['nameOrig', 'nameDest']\n",
    "\n",
    "colonnes_existantes = data1.columns.tolist()\n",
    "colonnes_a_supprimer = [colonne for colonne in var_catégorielle if colonne in colonnes_existantes]\n",
    "\n",
    "data = data1.drop(columns=colonnes_a_supprimer)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-chemical",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T14:35:36.977589Z",
     "iopub.status.busy": "2021-05-13T14:35:36.976615Z",
     "iopub.status.idle": "2021-05-13T14:36:24.317668Z",
     "shell.execute_reply": "2021-05-13T14:36:24.318189Z"
    },
    "papermill": {
     "duration": 47.70445,
     "end_time": "2021-05-13T14:36:24.318364",
     "exception": false,
     "start_time": "2021-05-13T14:35:36.613914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's turn non-numerical values into numbers\n",
    "for label, content in data.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        data[label] = pd.Categorical(content).codes+1\n",
    "\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce48db8",
   "metadata": {},
   "source": [
    "### Distribution  de fraude suivant type transfer ou cash_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6184b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spécifier l'axe des x et l'axe des y\n",
    "ax = data['isFraud'].value_counts().plot(\n",
    "kind='pie', \n",
    "figsize=(8,4),\n",
    "autopct = '%.2f%%', \n",
    "labels=df['isFraud'].value_counts().index,\n",
    "legend = True,\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "'Distributions des transactions fauduleuse et non frauduleuse', \n",
    "loc ='center',\n",
    "fontsize=12, \n",
    "fontweight='bold'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9383eb87",
   "metadata": {},
   "source": [
    "En analysant les résultats obtenus à partir de la matrice de corrélation, on observe que 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest' présentent une corrélation très élevée (corrélation de 1). Afin d'éviter la multicollinéarité  (La multicollinéarité est un terme utilisé en statistiques et en analyse de régression pour décrire une situation où deux ou plusieurs variables indépendantes dans un modèle statistique sont fortement corrélées entre elles) dans le modèle, il est possible de supprimer l'une des variables, d'appliquer l'Analyse en Composantes Principales (ACP) ou encore d'étudier la contribution de chaque variable en fonction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisons loption suprresion des l'un des variable\n",
    "\n",
    "var_catégorielle = [ 'oldbalanceOrg', 'newbalanceDest']\n",
    "\n",
    "colonnes_existantes = data.columns.tolist()\n",
    "colonnes_a_supprimer = [colonne for colonne in var_catégorielle if colonne in colonnes_existantes]\n",
    "\n",
    "data_model = data.drop(columns=colonnes_a_supprimer)\n",
    "data_model .columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58a6e4",
   "metadata": {},
   "source": [
    "## Text des modèles de Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-elimination",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T14:36:24.394866Z",
     "iopub.status.busy": "2021-05-13T14:36:24.393350Z",
     "iopub.status.idle": "2021-05-13T14:36:24.595754Z",
     "shell.execute_reply": "2021-05-13T14:36:24.595166Z"
    },
    "papermill": {
     "duration": 0.225454,
     "end_time": "2021-05-13T14:36:24.595921",
     "exception": false,
     "start_time": "2021-05-13T14:36:24.370467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data_model.drop('isFraud', axis=1)\n",
    "y = data_model['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Instanciation de PCA\n",
    "acp = PCA()\n",
    "\n",
    "# Calcul des composantes principales\n",
    "coord = acp.fit_transform(X)\n",
    "\n",
    "# Nombre de composantes calculées\n",
    "print(\"Nombre de composantes:\", acp.n_components_)\n",
    "\n",
    "# Variance expliquée pour chaque composante\n",
    "explained_variance = acp.explained_variance_ratio_\n",
    "\n",
    "# Cumul de la variance expliquée\n",
    "cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Affichage de la variance expliquée et du cumul\n",
    "for i, (var, cum_var) in enumerate(zip(explained_variance, cumulative_explained_variance), 1):\n",
    "    print(f\"Composante {i}: Variance expliquée = {var:.4f}, Cumul de variance expliquée = {cum_var:.4f}\")\n",
    "\n",
    "# Visualisation du cumul de variance expliquée\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(explained_variance) + 1), cumulative_explained_variance, marker='o')\n",
    "plt.xlabel(\"Nombre de composantes principales\")\n",
    "plt.ylabel(\"Cumul de variance expliquée\")\n",
    "plt.title(\"Variance expliquée et cumul de variance expliquée\")\n",
    "plt.show()\n",
    "threshold = 0.95  # Par exemple, choisir un seuil de 95%\n",
    "\n",
    "num_components_to_retain = np.argmax(cumulative_explained_variance >= threshold) + 1\n",
    "\n",
    "print(f\"\\nNombre de composantes pour conserver {threshold * 100}% de l'information: {num_components_to_retain}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-headquarters",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T14:36:24.637106Z",
     "iopub.status.busy": "2021-05-13T14:36:24.636009Z",
     "iopub.status.idle": "2021-05-13T14:36:26.463823Z",
     "shell.execute_reply": "2021-05-13T14:36:26.464290Z"
    },
    "papermill": {
     "duration": 1.850973,
     "end_time": "2021-05-13T14:36:26.464481",
     "exception": false,
     "start_time": "2021-05-13T14:36:24.613508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(37)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de l'ACP pour réduire la dimensionnalité\n",
    "n_components = 2 # Choix du nombre de composantes principales à conserver\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a2d50",
   "metadata": {},
   "source": [
    "### Test avec un modèle de deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb04fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b78bed99",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f63db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "sc=RobustScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test= sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc64d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Définition du modèle RandomForestClassifier avec class_weight='balanced'\n",
    "R1 = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Paramètres pour la Grid Search\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 80, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Appliquer la Grid Search pour RandomForestClassifier\n",
    "grid_search_rf = GridSearchCV(R1, param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres trouvés\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best Parameters for RandomForestClassifier:\", best_params_rf)\n",
    "\n",
    "# Utiliser le modèle avec les meilleurs paramètres\n",
    "R1_best = grid_search_rf.best_estimator_\n",
    "print(R1_best)\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "R1_best.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction et affichage de la matrice de confusion pour les données d'entraînement\n",
    "pred_train = R1_best.predict(X_train)\n",
    "c_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"Confusion Matrix (Train):\")\n",
    "print(c_train)\n",
    "\n",
    "# Prédiction et affichage de la matrice de confusion pour les données de test\n",
    "pred_test = R1_best.predict(X_test)\n",
    "c_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(c_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train, pred_train)\n",
    "test_accuracy = roc_auc_score(y_test, pred_test)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "plt.title('Matrice de confusion X_train')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.title('Matrice de confusion X_test')\n",
    "\n",
    "plt.show()\n",
    "print(classification_report(y_test, pred_test))\n",
    "sns.heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e022868",
   "metadata": {},
   "source": [
    "#### Test avec un model ensembliste : XGBClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22784d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'n_estimators': [10, 80, 100],\n",
    "              'gamma': [0, 0.01, 1],        \n",
    "              'max_depth': [7, 8, 10], \n",
    "              'colsample_bytree': [0.7, 1],\n",
    "              'learning_rate': [0.1, 0.01, 0.001],\n",
    "              'scale_pos_weight': [99],  \n",
    "             }\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "# Train the model with the best parametersbe\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and confusion matrices\n",
    "predict_train = model.predict(X_train)\n",
    "c_train = confusion_matrix(y_train, predict_train)\n",
    "\n",
    "predict_test = model.predict(X_test)\n",
    "c_test = confusion_matrix(y_test, predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train, predict_train)\n",
    "test_accuracy = roc_auc_score(y_test, predict_test)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b429113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "plt.title('Matrice de confusion X_train')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.title('Matrice de confusion X_test')\n",
    "\n",
    "plt.show()\n",
    "print(classification_report(y_test, predict_test))\n",
    "sns.heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc76d7",
   "metadata": {},
   "source": [
    "###  deep Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c596d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred1 = (model.predict(X_train)> 0.5).astype(\"int32\")\n",
    "c_train = confusion_matrix(y_train, pred1)\n",
    "pred = (model.predict(X_test)> 0.5).astype(\"int32\")\n",
    "c_test = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "\n",
    "\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.show()\n",
    "print(classification_report(y_test, pred))\n",
    "sns.heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47261c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train, pred1)\n",
    "test_accuracy = roc_auc_score(y_test, pred)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c7579",
   "metadata": {},
   "source": [
    "# Sous-echantillonage\n",
    "<a id=\"18\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8910e8",
   "metadata": {},
   "source": [
    "Dans cette partie nous essayons d'équilibrer les données de notre variable cible 'Class'. On utilisons Ainsi la méthode du sous-échantillonnage aléatoire ou 'Under-Sampling aléatoire L'objectif ici est de supprimer aléatoirement certaines observations de la classe majoritaire et de répéter l'opération jusqu'à ce que la classe majoritaire et minoritaire soit équilibrée.\n",
    "\n",
    "Le sous-échantillonnage peut être un bon choix lorsque nos donnéessont de taille importante. Mais son inconvénient est que parfois nous supprimons les informations qui peuvent être précieuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sample=RandomUnderSampler()\n",
    "X_train_samp, y_train_samp=sample.fit_resample(X_train,y_train )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014746b9",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Définition du modèle RandomForestClassifier\n",
    "R1 = RandomForestClassifier()\n",
    "\n",
    "# Paramètres pour la Grid Search\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 80, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Appliquer la Grid Search pour RandomForestClassifier\n",
    "grid_search_rf = GridSearchCV(R1, param_grid_rf, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search_rf.fit(X_train_samp, y_train_samp)\n",
    "\n",
    "# Meilleurs paramètres trouvés\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best Parameters for RandomForestClassifier:\", best_params_rf)\n",
    "\n",
    "# Utiliser le modèle avec les meilleurs paramètres\n",
    "R1_best = grid_search_rf.best_estimator_\n",
    "print(R1_best)\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "R1_best.fit(X_train_samp, y_train_samp)\n",
    "\n",
    "# Prédiction et affichage de la matrice de confusion pour les données d'entraînement\n",
    "pred_train = R1_best.predict(X_train)\n",
    "c_train = confusion_matrix(y_train_samp, pred_train)\n",
    "print(\"Confusion Matrix (Train):\")\n",
    "print(c_train)\n",
    "\n",
    "# Prédiction et affichage de la matrice de confusion pour les données de test\n",
    "pred_test = R1_best.predict(X_test)\n",
    "c_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(c_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1435d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train_samp, pred1)\n",
    "test_accuracy = roc_auc_score(y_test, pred)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e99ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "plt.title('Matrice de confusion X_train')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.title('Matrice de confusion X_test')\n",
    "\n",
    "plt.show()\n",
    "print(classification_report(y_test, pred))\n",
    "sns.heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132ab97",
   "metadata": {},
   "source": [
    "#### XGBCLASSIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'n_estimators': [10, 80, 100],\n",
    "              'gamma': [0, 0.01, 1],        \n",
    "              'max_depth': [7, 8, 10], \n",
    "              'colsample_bytree': [0.7, 1],\n",
    "              'learning_rate': [0.1, 0.01, 0.001],\n",
    "              'scale_pos_weight': [99],  \n",
    "             }\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='f1')\n",
    "grid_search.fit(X_train_samp, y_train_samp)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best parameters\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train_samp, y_train_samp)\n",
    "\n",
    "# Prediction and confusion matrices\n",
    "predict_train = model.predict(X_train_samp)\n",
    "c_train = confusion_matrix(y_train_samp, predict_train)\n",
    "\n",
    "predict_test = model.predict(X_test)\n",
    "c_test = confusion_matrix(y_test, predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train_samp, predict_train)\n",
    "test_accuracy = roc_auc_score(y_test, predict_test)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88268d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "plt.title('Matrice de confusion X_train')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.title('Matrice de confusion X_test')\n",
    "\n",
    "plt.show()\n",
    "print(classification_report(y_test, predict_test))\n",
    "sns.heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb4c6b",
   "metadata": {},
   "source": [
    "### Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccad2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_samp, y_train_samp, epochs=10, batch_size=32, validation_split=0.2, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d116b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred1 = (model.predict(X_train_samp)> 0.5).astype(\"int32\")\n",
    "c_train = confusion_matrix(y_train_samp, pred1)\n",
    "pred = (model.predict(X_test)> 0.5).astype(\"int32\")\n",
    "c_test = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "\n",
    "\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.show()\n",
    "print(classification_report(y_test, pred))\n",
    "sns.heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e08943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train_samp, pred1)\n",
    "test_accuracy = roc_auc_score(y_test, pred)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660de088",
   "metadata": {},
   "source": [
    "## OverSampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sample = SMOTE()\n",
    "X_train_sampOver, y_train_sampOver = sample.fit_resample(X_train, y_train)\n",
    "X_train_sampOver.shape, y_train_sampOver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "sample=RandomOverSampler()\n",
    "X_train_sampOver, y_train_sampOver = sample.fit_resample(X_train, y_train)\n",
    "X_train_sampOver.shape, y_train_sampOver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Définition du modèle RandomForestClassifier\n",
    "R1 = RandomForestClassifier()\n",
    "\n",
    "# Paramètres pour la Grid Search\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 80, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Appliquer la Grid Search pour RandomForestClassifier\n",
    "grid_search_rf = GridSearchCV(R1, param_grid_rf, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search_rf.fit(X_train_sampOver, y_train_sampOver)\n",
    "\n",
    "# Meilleurs paramètres trouvés\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best Parameters for RandomForestClassifier:\", best_params_rf)\n",
    "\n",
    "# Utiliser le modèle avec les meilleurs paramètres\n",
    "R1_best = grid_search_rf.best_estimator_\n",
    "print(R1_best)\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "R1_best.fit(X_train_sampOver, y_train_sampOver)\n",
    "\n",
    "# Prédiction et affichage de la matrice de confusion pour les données d'entraînement\n",
    "pred_train = R1_best.predict(X_train_sampOver)\n",
    "c_train = confusion_matrix(y_train_sampOver, pred_train)\n",
    "print(\"Confusion Matrix (Train):\")\n",
    "print(c_train)\n",
    "\n",
    "# Prédiction et affichage de la matrice de confusion pour les données de test\n",
    "pred_test = R1_best.predict(X_test)\n",
    "c_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(c_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3472b82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train_sampOver, pred_train)\n",
    "test_accuracy = roc_auc_score(y_test, pred_test)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "plt.title('Matrice de confusion X_train')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.title('Matrice de confusion X_test')\n",
    "\n",
    "plt.show()\n",
    "print(classification_report(y_test, pred_test))\n",
    "sns.heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f343e",
   "metadata": {},
   "source": [
    "### XGBCLASSIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a0d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'n_estimators': [10, 80, 100],\n",
    "              'gamma': [0, 0.01, 1],        \n",
    "              'max_depth': [7, 8, 10], \n",
    "              'colsample_bytree': [0.7, 1],\n",
    "              'learning_rate': [0.1, 0.01, 0.001],\n",
    "              'scale_pos_weight': [99],  \n",
    "             }\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='f1')\n",
    "grid_search.fit(X_train_sampOver, y_train_sampOver)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "# Train the model with the best parametersbe\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train_sampOver, y_train_sampOver)\n",
    "\n",
    "# Prediction and confusion matrices\n",
    "predict_train = model.predict(X_train_sampOver)\n",
    "c_train = confusion_matrix(y_train_sampOver, predict_train)\n",
    "\n",
    "predict_test = model.predict(X_test)\n",
    "c_test = confusion_matrix(y_test, predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130eab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train_sampOver, predict_train)\n",
    "test_accuracy = roc_auc_score(y_test, predict_test)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d898893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "plt.title('Matrice de confusion X_train')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.title('Matrice de confusion X_test')\n",
    "\n",
    "plt.show()\n",
    "print(classification_report(y_test, predict_test))\n",
    "sns.heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa2910",
   "metadata": {},
   "source": [
    "### Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_sampOver,y_train_sampOver, epochs=10, batch_size=32, validation_split=0.2, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296812df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred1 = (model.predict(X_train_sampOver)> 0.5).astype(\"int32\")\n",
    "c_train = confusion_matrix(y_train_sampOver, pred1)\n",
    "pred = (model.predict(X_test)> 0.5).astype(\"int32\")\n",
    "c_test = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(pd.DataFrame(np.hstack([c_train, c_test]), index=[\"y=0\", \"y=1\"],\n",
    "                            columns=\"train:y=0 train:y=1 test:y=0 test:y=1\".split()), \"\\n\\n\")\n",
    "\n",
    "\n",
    "print(c_train)\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(c_train,annot=True,cmap='Blues',fmt='0')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(c_test,annot=True,cmap='Reds',fmt='0',xticklabels='auto',\n",
    "    yticklabels='auto')\n",
    "plt.show()\n",
    "print(classification_report(y_test, pred))\n",
    "sns.heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcff09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "# evaluate\n",
    "train_accuracy = roc_auc_score(y_train_sampOver, pred1)\n",
    "test_accuracy = roc_auc_score(y_test, pred)\n",
    "print(\"train accurency\",train_accuracy)\n",
    "print(\"test accurency\",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa55c4",
   "metadata": {},
   "source": [
    "Précision (Precision) :\n",
    "\n",
    "Pour la classe 0 (non frauduleuse) : 1.00 (100%)\n",
    "Pour la classe 1 (frauduleuse) : 0.05 (5%)\n",
    "La précision mesure le nombre de vrais positifs divisé par le nombre total de prédictions positives. Pour la classe 0, toutes les prédictions positives sont correctes, ce qui donne une précision de 100%. Cependant, pour la classe 1, seulement 5% des prédictions positives sont correctes.\n",
    "Rappel (Recall ou Sensibilité) :\n",
    "\n",
    "Pour la classe 0 (non frauduleuse) : 0.96 (96%)\n",
    "Pour la classe 1 (frauduleuse) : 0.78 (78%)\n",
    "Le rappel mesure le nombre de vrais positifs divisé par le nombre total d'instances réellement positives. Pour la classe 0, 96% des transactions non frauduleuses sont correctement identifiées. Pour la classe 1, 78% des transactions frauduleuses sont correctement identifiées.\n",
    "Score F1 (F1 Score) :\n",
    "\n",
    "Pour la classe 0 : 0.98\n",
    "Pour la classe 1 : 0.09\n",
    "Le score F1 est la moyenne harmonique de la précision et du rappel. Il prend en compte les faux positifs et faux négatifs. Une valeur élevée du score F1 indique un équilibre entre la précision et le rappel. La classe 0 a un score F1 élevé, mais la classe 1 a un score F1 relativement bas.\n",
    "Accuracy (Précision globale) :\n",
    "\n",
    "Accuracy : 0.95 (95%)\n",
    "L'accuracy mesure le nombre total de prédictions correctes divisé par le nombre total d'instances. La précision globale est élevée à 95%, mais cela peut être trompeur dans des situations de classes très déséquilibrées, comme dans le cas des transactions frauduleuses.\n",
    "Macro AVG (Moyenne Macro) :\n",
    "\n",
    "Précision macro avg : 0.52\n",
    "Rappel macro avg : 0.87\n",
    "Score F1 macro avg : 0.53\n",
    "La moyenne macro calcule les métriques pour chaque classe séparément et fait la moyenne. Elle donne à chaque classe un poids égal, indépendamment de sa taille.\n",
    "Weighted AVG (Moyenne Pondérée) :\n",
    "\n",
    "Précision weighted avg : 1.00\n",
    "Rappel weighted avg : 0.95\n",
    "Score F1 weighted avg : 0.97\n",
    "La moyenne pondérée calcule les métriques pour chaque classe séparément, mais elle les pondère en fonction du nombre d'instances dans chaque classe. Cela donne une meilleure indication de la performance du modèle dans des situations de classes déséquilibrées.\n",
    "En résumé, votre modèle semble avoir une très bonne précision globale, mais il présente des performances inégales entre les deux classes en raison du déséquilibre des données. La classe 1 (frauduleuse) a une précision et un rappel relativement bas, indiquant des difficultés à bien la prédire. Vous pourriez envisager d'explorer des techniques d'équilibrage de classe ou d'autres ajustements du modèle pour améliorer ces résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48090a6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2161693",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff13ba",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14245.887294,
   "end_time": "2021-05-13T18:32:18.654179",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-13T14:34:52.766885",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
